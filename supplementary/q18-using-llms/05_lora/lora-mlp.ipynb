{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/MLQandAI/blob/main/supplementary/q18-using-llms/05_lora/lora-mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2abd10e-e63e-4904-badf-5a16409503b1",
      "metadata": {
        "id": "d2abd10e-e63e-4904-badf-5a16409503b1"
      },
      "source": [
        "# LoRA -- 다층 퍼셉트론 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "263e27da-47c7-4030-83c6-bf5f7e8bef74",
      "metadata": {
        "id": "263e27da-47c7-4030-83c6-bf5f7e8bef74"
      },
      "source": [
        "(LLM이 아니라) 다층 퍼셉트론을 사용해 LoRA([https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685))를 밑바닥부터 구현하여 작동 방식을 이해하기 위한 노트북입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c1c52f02-94fb-4f45-902e-79126e27347d",
      "metadata": {
        "id": "c1c52f02-94fb-4f45-902e-79126e27347d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629ec66a-eb81-40a5-ae3d-d5c1d2a7e390",
      "metadata": {
        "id": "629ec66a-eb81-40a5-ae3d-d5c1d2a7e390"
      },
      "source": [
        "## 설정과 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ade5e86-8bd8-4a35-8db1-44451601b292",
      "metadata": {
        "id": "4ade5e86-8bd8-4a35-8db1-44451601b292",
        "outputId": "adb710db-1074-48a8-db40-cd60de41aef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.53MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 133kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.78MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "이미지 배치 크기: torch.Size([64, 1, 28, 28])\n",
            "레이블 배치 크기: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "### 설정\n",
        "##########################\n",
        "\n",
        "# 장치\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "##########################\n",
        "### MNIST 데이터셋\n",
        "##########################\n",
        "\n",
        "# transforms.ToTensor()으로 입력 이미지를 0-1 범위로 변환합니다\n",
        "train_dataset = datasets.MNIST(root='data',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='data',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False)\n",
        "\n",
        "# 데이터셋 확인\n",
        "for images, labels in train_loader:\n",
        "    print('이미지 배치 크기:', images.shape)\n",
        "    print('레이블 배치 크기:', labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "394e5da8-2978-40f0-bca7-b79e8e35734f",
      "metadata": {
        "id": "394e5da8-2978-40f0-bca7-b79e8e35734f"
      },
      "source": [
        "# (LoRA를 사용하지 않는) 다층 퍼셉트론 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e905c42-7f59-4a08-b6c5-a10f99f33e9e",
      "metadata": {
        "id": "7e905c42-7f59-4a08-b6c5-a10f99f33e9e"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "### 모델\n",
        "##########################\n",
        "\n",
        "# 하이퍼파라미터\n",
        "random_seed = 123\n",
        "learning_rate = 0.005\n",
        "num_epochs = 2\n",
        "\n",
        "# 구조\n",
        "num_features = 784\n",
        "num_hidden_1 = 128\n",
        "num_hidden_2 = 256\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "class MultilayerPerceptron(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features, num_hidden_1, num_hidden_2, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(num_features, num_hidden_1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_hidden_1, num_hidden_2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_hidden_2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "model_pretrained = MultilayerPerceptron(\n",
        "    num_features=num_features,\n",
        "    num_hidden_1=num_hidden_1,\n",
        "    num_hidden_2=num_hidden_2,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "model_pretrained.to(DEVICE)\n",
        "optimizer_pretrained = torch.optim.Adam(model_pretrained.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cf31624a-d950-402f-a564-2e7fb63db8a4",
      "metadata": {
        "id": "cf31624a-d950-402f-a564-2e7fb63db8a4"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.view(-1, 28*28).to(device)\n",
        "            targets = targets.to(device)\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "        return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "def train(num_epochs, model, optimizer, train_loader, device):\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "            features = features.view(-1, 28*28).to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # 정방향 계산과 역전파\n",
        "            logits = model(features)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # 모델 파라미터 업데이트\n",
        "            optimizer.step()\n",
        "\n",
        "            # 로깅\n",
        "            if not batch_idx % 400:\n",
        "                print('에포크: %03d/%03d | 배치 %03d/%03d | 손실: %.4f'\n",
        "                      % (epoch+1, num_epochs, batch_idx,\n",
        "                          len(train_loader), loss))\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            print('에포크: %03d/%03d 훈련 정확도: %.2f%%' % (\n",
        "                  epoch+1, num_epochs,\n",
        "                  compute_accuracy(model, train_loader, device)))\n",
        "\n",
        "        print('소요 시간: %.2f min' % ((time.time() - start_time)/60))\n",
        "\n",
        "    print('총 훈련 시간: %.2f min' % ((time.time() - start_time)/60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f47cfe4e-65eb-440e-b922-17c6dee7d7e2",
      "metadata": {
        "id": "f47cfe4e-65eb-440e-b922-17c6dee7d7e2",
        "outputId": "3df5c950-aacd-40d4-a15a-e7357de7b3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 001/002 | 배치 000/938 | 손실: 2.2971\n",
            "에포크: 001/002 | 배치 400/938 | 손실: 0.1529\n",
            "에포크: 001/002 | 배치 800/938 | 손실: 0.1094\n",
            "에포크: 001/002 훈련 정확도: 96.01%\n",
            "소요 시간: 0.22 min\n",
            "에포크: 002/002 | 배치 000/938 | 손실: 0.1192\n",
            "에포크: 002/002 | 배치 400/938 | 손실: 0.0593\n",
            "에포크: 002/002 | 배치 800/938 | 손실: 0.0806\n",
            "에포크: 002/002 훈련 정확도: 97.23%\n",
            "소요 시간: 0.43 min\n",
            "총 훈련 시간: 0.43 min\n",
            "테스트 정확도: 96.73%\n"
          ]
        }
      ],
      "source": [
        "train(num_epochs, model_pretrained, optimizer_pretrained, train_loader, DEVICE)\n",
        "print(f'테스트 정확도: {compute_accuracy(model_pretrained, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb3480b9-aea5-411e-b252-d7fc8a5dd21d",
      "metadata": {
        "id": "fb3480b9-aea5-411e-b252-d7fc8a5dd21d"
      },
      "source": [
        "# LoRA를 사용한 다층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b9d281-22ba-4120-af95-f6b95adcaa03",
      "metadata": {
        "id": "36b9d281-22ba-4120-af95-f6b95adcaa03"
      },
      "source": [
        "## LoRA 층을 추가하여 모델 수정하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "215795c5-c0d4-4886-b4d6-a5a0e7cc8c7e",
      "metadata": {
        "id": "215795c5-c0d4-4886-b4d6-a5a0e7cc8c7e"
      },
      "outputs": [],
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "        super().__init__()\n",
        "        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())\n",
        "        self.A = nn.Parameter(torch.randn(in_dim, rank) * std_dev)\n",
        "        self.B = nn.Parameter(torch.zeros(rank, out_dim))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.alpha * (x @ self.A @ self.B)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinearWithLoRA(nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(\n",
        "            linear.in_features, linear.out_features, rank, alpha\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)\n",
        "\n",
        "\n",
        "# 이 코드는 LinearWithLoRA와 동등합니다.\n",
        "class LinearWithLoRAMerged(nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(\n",
        "            linear.in_features, linear.out_features, rank, alpha\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        lora = self.lora.A @ self.lora.B\n",
        "        combined_weight = self.linear.weight + lora.T\n",
        "        return F.linear(x, combined_weight, self.linear.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0441c93f-0ee5-4003-acc3-f24541f06c66",
      "metadata": {
        "id": "0441c93f-0ee5-4003-acc3-f24541f06c66",
        "outputId": "7c9b7af5-c3e5-41d5-8c0d-3b87be674529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 출력: tensor([[0.6639, 0.4487]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "layer = nn.Linear(10, 2)\n",
        "x = torch.randn((1, 10))\n",
        "\n",
        "print(\"원본 출력:\", layer(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b132184a-f87e-423f-850a-2dc44fe76770",
      "metadata": {
        "id": "b132184a-f87e-423f-850a-2dc44fe76770",
        "outputId": "5004995f-990a-4f86-e85b-08a7a710962f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA 출력: tensor([[0.6639, 0.4487]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "layer_lora_1 = LinearWithLoRA(layer, rank=2, alpha=4)\n",
        "\n",
        "print(\"LoRA 출력:\", layer_lora_1(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f555c364-9c5f-4a20-8c8c-feb830131555",
      "metadata": {
        "id": "f555c364-9c5f-4a20-8c8c-feb830131555",
        "outputId": "db2952e7-fa07-4edc-9f51-c3966b20ef69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA 출력: tensor([[0.6639, 0.4487]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "layer_lora_2 = LinearWithLoRAMerged(layer, rank=2, alpha=4)\n",
        "print(\"LoRA 출력:\", layer_lora_2(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dc66ffa1-5822-4833-b636-d3a8170e84a2",
      "metadata": {
        "id": "dc66ffa1-5822-4833-b636-d3a8170e84a2",
        "outputId": "dec047c7-d98f-4ba6-fe8a-c789be0163f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultilayerPerceptron(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b00a7e8f-09ff-499e-b593-3f6dac87f1bf",
      "metadata": {
        "id": "b00a7e8f-09ff-499e-b593-3f6dac87f1bf"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "model_lora = copy.deepcopy(model_pretrained)\n",
        "model_dora = copy.deepcopy(model_pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b1e3ef6f-255c-4c71-9da5-7d06d8c439a3",
      "metadata": {
        "id": "b1e3ef6f-255c-4c71-9da5-7d06d8c439a3",
        "outputId": "d6911665-1209-41e8-b151-3238ef5455f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultilayerPerceptron(\n",
              "  (layers): Sequential(\n",
              "    (0): LinearWithLoRA(\n",
              "      (linear): Linear(in_features=784, out_features=128, bias=True)\n",
              "      (lora): LoRALayer()\n",
              "    )\n",
              "    (1): ReLU()\n",
              "    (2): LinearWithLoRA(\n",
              "      (linear): Linear(in_features=128, out_features=256, bias=True)\n",
              "      (lora): LoRALayer()\n",
              "    )\n",
              "    (3): ReLU()\n",
              "    (4): LinearWithLoRA(\n",
              "      (linear): Linear(in_features=256, out_features=10, bias=True)\n",
              "      (lora): LoRALayer()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model_lora.layers[0] = LinearWithLoRA(model_lora.layers[0], rank=4, alpha=8)\n",
        "model_lora.layers[2] = LinearWithLoRA(model_lora.layers[2], rank=4, alpha=8)\n",
        "model_lora.layers[4] = LinearWithLoRA(model_lora.layers[4], rank=4, alpha=8)\n",
        "\n",
        "model_lora.to(DEVICE)\n",
        "optimizer_lora = torch.optim.Adam(model_lora.parameters(), lr=learning_rate)\n",
        "model_lora"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9756742d-f574-400a-8d4e-cc55233df83c",
      "metadata": {
        "id": "9756742d-f574-400a-8d4e-cc55233df83c"
      },
      "source": [
        "LoRA 층을 추가했지만 아직 훈련하지 않았습니다. 따라서 LoRA 층이 있는 모델과 그렇지 않은 모델의 예측 성능은 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d2ac620b-2fdf-4b94-92bb-f8d00e640306",
      "metadata": {
        "id": "d2ac620b-2fdf-4b94-92bb-f8d00e640306",
        "outputId": "7746e859-c0b3-4f28-d906-962eafb63855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 모델의 테스트 정확도: 96.73%\n",
            "LoRA 모델의 테스트 정확도: 96.73%\n"
          ]
        }
      ],
      "source": [
        "print(f'원본 모델의 테스트 정확도: {compute_accuracy(model_pretrained, test_loader, DEVICE):.2f}%')\n",
        "print(f'LoRA 모델의 테스트 정확도: {compute_accuracy(model_lora, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ceed732-7989-4f01-a5a1-1036eb41512d",
      "metadata": {
        "id": "4ceed732-7989-4f01-a5a1-1036eb41512d"
      },
      "source": [
        "## LoRA 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a35d4c20-f754-4e82-85a1-ad19a30b3dfe",
      "metadata": {
        "id": "a35d4c20-f754-4e82-85a1-ad19a30b3dfe"
      },
      "outputs": [],
      "source": [
        "def freeze_linear_layers(model):\n",
        "    for child in model.children():\n",
        "        if isinstance(child, nn.Linear):\n",
        "            for param in child.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            # 하위 모듈 중에서 선형 층을 재귀적으로 동결합니다.\n",
        "            freeze_linear_layers(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "88454690-abe6-49de-986e-9a6fe7883000",
      "metadata": {
        "id": "88454690-abe6-49de-986e-9a6fe7883000",
        "outputId": "50165c21-44af-4db8-c486-82491685ef14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.linear.weight: False\n",
            "layers.0.linear.bias: False\n",
            "layers.0.lora.A: True\n",
            "layers.0.lora.B: True\n",
            "layers.2.linear.weight: False\n",
            "layers.2.linear.bias: False\n",
            "layers.2.lora.A: True\n",
            "layers.2.lora.B: True\n",
            "layers.4.linear.weight: False\n",
            "layers.4.linear.bias: False\n",
            "layers.4.lora.A: True\n",
            "layers.4.lora.B: True\n"
          ]
        }
      ],
      "source": [
        "freeze_linear_layers(model_lora)\n",
        "\n",
        "# 선형 층이 동결되었는지 확인합니다.\n",
        "for name, param in model_lora.named_parameters():\n",
        "    print(f\"{name}: {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1b807c7b-8d4a-4a1e-8a56-42bbdbc82fed",
      "metadata": {
        "id": "1b807c7b-8d4a-4a1e-8a56-42bbdbc82fed",
        "outputId": "c3e3352d-43bb-4782-f413-cfe268aa143c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 001/002 | 배치 000/938 | 손실: 0.1210\n",
            "에포크: 001/002 | 배치 400/938 | 손실: 0.2014\n",
            "에포크: 001/002 | 배치 800/938 | 손실: 0.1422\n",
            "에포크: 001/002 훈련 정확도: 97.47%\n",
            "소요 시간: 0.23 min\n",
            "에포크: 002/002 | 배치 000/938 | 손실: 0.0776\n",
            "에포크: 002/002 | 배치 400/938 | 손실: 0.0727\n",
            "에포크: 002/002 | 배치 800/938 | 손실: 0.0063\n",
            "에포크: 002/002 훈련 정확도: 97.96%\n",
            "소요 시간: 0.44 min\n",
            "총 훈련 시간: 0.44 min\n",
            "미세 튜닝한 LoRA 모델의 테스트 정확도: 97.04%\n"
          ]
        }
      ],
      "source": [
        "optimizer_lora = torch.optim.Adam(model_lora.parameters(), lr=learning_rate)\n",
        "train(num_epochs, model_lora, optimizer_lora, train_loader, DEVICE)\n",
        "print(f'미세 튜닝한 LoRA 모델의 테스트 정확도: {compute_accuracy(model_lora, test_loader, DEVICE):.2f}%')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}