{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/MLQandAI/blob/main/supplementary/q18-using-llms/03_retrieval-augmented-generation/retrieval-augmented-generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvOMyy2FL-Kc"
      },
      "source": [
        "# Llama Index를 사용한 RAG 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ng2yBUL-Kd"
      },
      "source": [
        "<img src=\"https://github.com/rickiepark/MLQandAI/blob/main/supplementary/q18-using-llms/03_retrieval-augmented-generation/images/rag-1.webp?raw=1\" width=700>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index llama-index-embeddings-huggingface llama-index-llms-huggingface"
      ],
      "metadata": {
        "id": "IpCLbZ6-MDtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet watermark\n",
        "\n",
        "%load_ext watermark\n",
        "%watermark -p torch,llama_index"
      ],
      "metadata": {
        "id": "ZqIEyFuFMFmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EwVkhh3L-Kd"
      },
      "source": [
        "### 1) 임베딩 모델과 LLM을 로드합니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***mistralai/Mistral-7B-Instruct-v0.2을 사용하려면 먼저 [허깅페이스 사이트](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2])에서 사용 허락을 받아야 합니다.***"
      ],
      "metadata": {
        "id": "9wPtOyw_MJkr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiZ_VKcFL-Ke",
        "outputId": "77d8a8b8-d05e-4bd0-9ef1-c3f2de0934a7",
        "colab": {
          "referenced_widgets": [
            "2d6dd568bd5942aca2b4b1990dced1c0",
            "36d2e512cb794ccd992ea0167d89a4b1",
            "510181fb957d4aa8b207e5db6bf2670c",
            "f271bb19ecbe411193f930b0e911cd3d",
            "7ffda14ee1a342188e0b802c2a04701b",
            "5ae79ed84cc942be877a84f3ad20246b",
            "1634e2eb83ab488084a421fc887f02a8",
            "17d7ef95ba824187ab1f393fc16640c4",
            "706913e2c5664880aec083155d25c65a",
            "d7e48b4b2c454791bba4154c93a28a94",
            "031abb874a614b01801da528b209f840",
            "af903888c44b4719adea490d3112ff72"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d6dd568bd5942aca2b4b1990dced1c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36d2e512cb794ccd992ea0167d89a4b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "510181fb957d4aa8b207e5db6bf2670c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f271bb19ecbe411193f930b0e911cd3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ffda14ee1a342188e0b802c2a04701b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ae79ed84cc942be877a84f3ad20246b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1634e2eb83ab488084a421fc887f02a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17d7ef95ba824187ab1f393fc16640c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "706913e2c5664880aec083155d25c65a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7e48b4b2c454791bba4154c93a28a94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "031abb874a614b01801da528b209f840",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af903888c44b4719adea490d3112ff72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from llama_index.core import Settings, PromptTemplate\n",
        "from llama_index.core.embeddings import resolve_embed_model\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "import torch\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "Settings.llm = HuggingFaceLLM(\n",
        "    context_window=2048,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.25, \"do_sample\": False},\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    device_map=\"auto\",\n",
        "\n",
        "    model_kwargs={\n",
        "        \"torch_dtype\": torch.bfloat16,\n",
        "        # 메모리가 제한된 소규모 GPU를 사용하기 때문에 True로 설정합니다.\n",
        "        # 고성능 GPU를 사용하여 속도를 높이려면 False로 지정하세요.\n",
        "        \"offload_buffers\": True,\n",
        "    }\n",
        ")\n",
        "\n",
        "Settings.chunk_size = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfO9Oh0GL-Kf"
      },
      "source": [
        "### 2) 데이터를 로드하고 문서를 읽습니다"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/rickiepark/MLQandAI/refs/heads/main/supplementary/q18-using-llms/03_retrieval-augmented-generation/sample-data/Basic-Scientific-Food-Preparation-Lab-Manual.txt"
      ],
      "metadata": {
        "id": "hvIlZMPnMS22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiWPS3EdL-Kf",
        "outputId": "3516e29a-7b19-405c-a4fd-f5c91f8bb95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read documents: {'Basic-Scientific-Food-Preparation-Lab-Manual.pdf', 'Basic-Scientific-Food-Preparation-Lab-Manual.txt'}\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "data_dir = \"./\"\n",
        "\n",
        "documents = SimpleDirectoryReader(data_dir).load_data()\n",
        "\n",
        "# 무결성 검사\n",
        "unique_docs = set(d.metadata[\"file_name\"] for d in documents)\n",
        "print(f\"읽은 문서: {unique_docs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6B9LPVYL-Kf"
      },
      "source": [
        "### 3) 벡터 데이터베이스를 만듭니다\n",
        "\n",
        "- VectorStoreIndex는 인메모리 벡터 데이터베이스입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MJdEHm0L-Kg",
        "outputId": "f5dd86ca-84d1-4078-8167-48d0a8131473",
        "colab": {
          "referenced_widgets": [
            "b7f6a80b589e4e768aee1d065e5f0eaf",
            "bc68b7f799e74a568e48e1a844efacd3"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7f6a80b589e4e768aee1d065e5f0eaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/252 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc68b7f799e74a568e48e1a844efacd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/567 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database consists of 252 chunks\n"
          ]
        }
      ],
      "source": [
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "num_chunks = len(documents)\n",
        "print(f\"데이터베이스는 {num_chunks}개의 청크로 구성됩니다\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHZOYJVvL-Kg"
      },
      "source": [
        "### 4) 사용자 정의 프롬프트 템플릿을 준비합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtI-lFrLL-Kg"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "template = (\n",
        "    \"We have provided context information below. \\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"{context_str}\"\n",
        "    \"\\n---------------------\\n\"\n",
        "    \"Given this information, please answer the question: {query_str}\\n\"\n",
        ")\n",
        "qa_template = PromptTemplate(template)\n",
        "query_engine = index.as_query_engine()\n",
        "query_engine.update_prompts(\n",
        "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM_VEwT9L-Kg"
      },
      "source": [
        "### 5) 벡터 데이터베이스에 쿼리를 수행합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw9utP5pL-Kg",
        "outputId": "a30eac91-bdc4-4996-d58c-ba395c6f6f36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.25` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dehydration is a method of preserving food by removing most of the water content. It can be done through various methods such as sun drying, oven drying, or using a dehydrator. Properly dehydrated food can be stored for long periods of time without spoiling and can be rehydrated or used as is for consumption. In this lab, students will be pretreating, drying, storing, and serving some commonly dehydrated fruits and vegetables, and observing the characteristics of various dried fruits.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What is dehydration?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KMEnt9XL-Kg",
        "outputId": "bf5cb85d-564d-43ec-f35f-61fce9f43129"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer: 2 tbsp. butter are required for the Cream Puffs.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"How many tbsp. butter to use for the Cream Puffs?\")\n",
        "print(response)\n",
        "# 정답은 2입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i25a74J1L-Kh",
        "outputId": "3c4dc4f2-e537-466a-b184-de40f3a395be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer: 2 tbsp. butter are required for the Cream Puffs.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"How many tbsp. butter to use for the Cream Puffs?\")\n",
        "print(response)\n",
        "# 정답은 2입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YUyi05OL-Kh",
        "outputId": "6d689e75-a75e-4105-d147-3ffb0fa02a0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The toppings for the Braided Bread of the Braids, Coffeecake, and Sweet Rolls recipe are:\n",
            "\n",
            "1. 2 tsp. caraway seeds and ½ cup shredded Cheddar cheese.\n",
            "2. ½ cup diced Swiss cheese and paprika.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"What are the toppings for the Braided Bread \"\n",
        "    \"of the Braids, Coffeecake, and Sweet Rolls recipe?\"\n",
        ")\n",
        "print(response)\n",
        "# 정답은 다음과 같습니다.\n",
        "# 2 tsp. caraway seeds and ½ cup shredded Cheddar cheese.\n",
        "# ½ cup diced Swiss cheese and paprika.\n",
        "# ..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}