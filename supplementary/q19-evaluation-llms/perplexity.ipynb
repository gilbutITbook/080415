{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/MLQandAI/blob/main/supplementary/q19-evaluation-llms/perplexity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bf02855-2a2a-433f-bc8a-883abf99ee34",
      "metadata": {
        "id": "9bf02855-2a2a-433f-bc8a-883abf99ee34"
      },
      "source": [
        "# 혼잡도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61c9de47-7f26-4c77-8c8f-0592716c337b",
      "metadata": {
        "id": "61c9de47-7f26-4c77-8c8f-0592716c337b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_perplexity(probabilities):\n",
        "    log_probs = np.log2(probabilities)\n",
        "    avg_log_prob = np.mean(log_probs)\n",
        "    perplexity = 2 ** (-avg_log_prob)\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d17c850-0867-4196-9477-895b879e975a",
      "metadata": {
        "id": "2d17c850-0867-4196-9477-895b879e975a",
        "outputId": "93cb33e7-e597-4e2e-a05e-ed199a4213f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1의 혼잡도: 1.0567214564189926\n"
          ]
        }
      ],
      "source": [
        "true_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "sentence_1 = \"The fast black cat jumps over the lazy dog\"\n",
        "\n",
        "s1_word_proba = [0.99, 0.85, 0.89, 0.94, 0.99, 0.99, 0.99, 0.99, 0.90]\n",
        "perplexity = calculate_perplexity(s1_word_proba)\n",
        "print(\"문장 1의 혼잡도:\", perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b50c6432-b7e2-4400-8ef1-4ed393019444",
      "metadata": {
        "id": "b50c6432-b7e2-4400-8ef1-4ed393019444",
        "outputId": "ceea53ea-84a4-484f-eb75-1598b1d1e5d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 2의 혼잡도: 2.2188609051008896\n"
          ]
        }
      ],
      "source": [
        "sentence_2 = \"The bold orange car drove by the lazy dog\"\n",
        "\n",
        "s2_word_proba = [0.99, 0.65, 0.13, 0.05, 0.21, 0.99, 0.99, 0.99, 0.90]\n",
        "perplexity = calculate_perplexity(s2_word_proba)\n",
        "print(\"문장 2의 혼잡도:\", perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747e4746-db4f-4dce-9232-fd681ccdc463",
      "metadata": {
        "id": "747e4746-db4f-4dce-9232-fd681ccdc463"
      },
      "source": [
        "## 크로스 엔트로피와의 관계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "30d5ea03-5576-4ac3-9acd-12deae2004ba",
      "metadata": {
        "id": "30d5ea03-5576-4ac3-9acd-12deae2004ba"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(p, q):\n",
        "    # Clip q to avoid log2(0) which is undefined\n",
        "    q = np.clip(q, 1e-10, 1.0)\n",
        "    H = -np.sum(p * np.log2(q))\n",
        "\n",
        "    return H\n",
        "\n",
        "n = len(s1_word_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fd3a9a63-2f89-45e9-a088-c97edd6744e5",
      "metadata": {
        "id": "fd3a9a63-2f89-45e9-a088-c97edd6744e5",
        "outputId": "41b7366e-0c6d-45e9-b4c8-0caacfa7e5c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7163562924630626"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "cross_entropy(np.ones(n), s1_word_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "77d3c672-5688-4131-a093-6ed099398f10",
      "metadata": {
        "id": "77d3c672-5688-4131-a093-6ed099398f10",
        "outputId": "6e00b192-f8e8-4e73-ed58-5ce326233938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0567214564189926"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "2**(cross_entropy(np.ones(n), s1_word_proba) / n )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "678e6e34-2e7c-41e8-939d-7e061e06e5c0",
      "metadata": {
        "id": "678e6e34-2e7c-41e8-939d-7e061e06e5c0",
        "outputId": "6f5b5e54-960f-448e-9566-cf98c1ce0f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0567214564189926"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "calculate_perplexity(s1_word_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3dcf75-5218-4ed0-95cc-7b4b726827e8",
      "metadata": {
        "id": "3f3dcf75-5218-4ed0-95cc-7b4b726827e8"
      },
      "source": [
        "## TorchMetrics를 사용해 혼잡도 계산하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "3J0J9bfaknqL",
        "outputId": "93ad6041-f780-45cb-ce0f-d9f5ea5e95a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3J0J9bfaknqL",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "481d91c8-270b-4c05-934c-1976e3e2f890",
      "metadata": {
        "id": "481d91c8-270b-4c05-934c-1976e3e2f890"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.text import Perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9669c09-8409-4d30-abb6-67676ea8a545",
      "metadata": {
        "id": "c9669c09-8409-4d30-abb6-67676ea8a545"
      },
      "source": [
        "Torchmetrics의 혼잡도는 `predictions`과 `target` 변수를 받습니다.\n",
        "\n",
        "`predictions`의 크기는 `[batch_size, seq_len, vocab_size]`이고, `target`의 크기는 `[batch_size, seq_len]`로 가정합니다.\n",
        "\n",
        "문장 하나에 대해 살펴 보기 때문에 배치 크기는 1입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dc1de00f-d527-46cb-8db9-4bd6a59463c3",
      "metadata": {
        "id": "dc1de00f-d527-46cb-8db9-4bd6a59463c3"
      },
      "outputs": [],
      "source": [
        "sentence_1 = \"The fast black cat jumps over the lazy dog\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "262a7b52-af5e-4a68-b969-1735bfec4bd5",
      "metadata": {
        "id": "262a7b52-af5e-4a68-b969-1735bfec4bd5"
      },
      "source": [
        "이 노트북에서는 훈련 세트에 있는 고유한 단어의 모음인 어휘 사전을 따로 만들지 않았습니다. 간단히 어휘 사전에 다음 단어들이 포함되어 있다고 가정해 보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c5c781d9-d1ab-4d71-a4ca-68397880b8de",
      "metadata": {
        "id": "c5c781d9-d1ab-4d71-a4ca-68397880b8de"
      },
      "outputs": [],
      "source": [
        "vocab = {\n",
        "    0: \"The\",\n",
        "    1: \"quick\",\n",
        "    2: \"brown\",\n",
        "    3: \"fox\",\n",
        "    4: \"jumps\",\n",
        "    5: \"over\",\n",
        "    6: \"the\",\n",
        "    7: \"lazy\",\n",
        "    8: \"dog\",\n",
        "    9: \"fast\",\n",
        "    10: \"black\",\n",
        "    11: \"cat\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289e9648-1270-4c79-b7c5-be6aa3f4ebf0",
      "metadata": {
        "id": "289e9648-1270-4c79-b7c5-be6aa3f4ebf0"
      },
      "source": [
        "어휘 사전에 12개의 단어가 있으므로 모델의 출력은 12차원의 확률 벡터입니다. 따라서 9개의 단어로 구성된 문장(\"The fast black cat jumps over the lazy dog\")을 입력하면 1x9x12 차원 텐서가 출력됩니다.\n",
        "\n",
        "앞서 단어 확률을 다음과 같이 정의했습니다.\n",
        "\n",
        "```python\n",
        "s1_word_proba = [0.99, 0.85, 0.89, 0.99, 0.99, 0.99, 0.99, 0.99]\n",
        "```\n",
        "\n",
        "아래 표현에서 각 단어에 대응하는 어휘 사전 인덱스의 위치에 이 확률 값이 놓입니다.\n",
        "\n",
        "```python\n",
        "vocab = {\n",
        "    0: \"The\",\n",
        "    1: \"quick\",\n",
        "    2: \"brown\",\n",
        "    3: \"fox\",\n",
        "    4: \"jumps\",\n",
        "    5: \"over\",\n",
        "    6: \"the\",\n",
        "    7: \"lazy\",\n",
        "    8: \"dog\",\n",
        "    9: \"fast\",\n",
        "    10: \"black\",\n",
        "    11: \"cat\",\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e71aa61-d3cd-4cb2-b271-5a766f9ceaf4",
      "metadata": {
        "id": "8e71aa61-d3cd-4cb2-b271-5a766f9ceaf4",
        "outputId": "eaca6786-866d-4e68-9e0a-2d313c672024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "model_outputs = torch.tensor([[\n",
        "    [0.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01], # The, 인덱스 0\n",
        "    [0.0, 0.0, 0.0, 0.0, 0.02, 0.05, 0.02, 0.01, 0.05, 0.85, 0.00, 0.00], # fast, 인덱스 9\n",
        "    [0.01, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.89, 0.0], # black, 인덱스 10\n",
        "    [0.0, 0.0, 0.0, 0.01, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.94], # cat, 인덱스 11\n",
        "    [0.0, 0.01, 0.0, 0.0, 0.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], # jumps, 인덱스 4\n",
        "    [0.0, 0.0, 0.005, 0.005, 0.0, 0.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], # over, 인덱스 5\n",
        "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99, 0.0, 0.0, 0.01, 0.0, 0.0], # the, 인덱스 6\n",
        "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99, 0.01, 0.0, 0.0, 0.0], # lazy, 인덱스 7\n",
        "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.04, 0.0, 0.90, 0.0, 0.0, 0.01], # dog, 인덱스 8\n",
        "]])\n",
        "\n",
        "# 각 행의 합은 1이 되어야 합니다.\n",
        "print(model_outputs.sum(axis=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2bed18-f7c6-4d5c-8967-d3d6685b1bf3",
      "metadata": {
        "id": "cb2bed18-f7c6-4d5c-8967-d3d6685b1bf3"
      },
      "source": [
        "위의 벡터 리스트는 LLM이 반환하는 확률 벡터를 나타냅니다. 벡터 하나가 단어 하나에 대응됩니다. 각 행의 확률 합은 1이 되어야 합니다.\n",
        "\n",
        "예를 들어 첫 번째 행을 살펴 보죠.\n",
        "\n",
        "```\n",
        "[0.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01], # The, 인덱스 0\n",
        "```\n",
        "\n",
        "모델이 첫 번째 단어(\"The\")에 0.99의 확률을 할당하고, 마지막 단어(\"cat\")은 0.01의 확률을 할당합니다. 그외 나머지 단어의 확률은 모두 0입니다.\n",
        "\n",
        "**이 확률은 임의로 지정한 것입니다. 실제로는 LLM이 이런 확률을 만들지만 여기서는 간단한 예를 위해 생략합니다.**\n",
        "\n",
        "그다음 단어 인덱스가 담겨 있는 타깃 벡터를 사용해 타깃 단어 인덱스에 해당하는 확률을 얻을 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "df3e9250-f033-4a19-906a-267db2508f26",
      "metadata": {
        "id": "df3e9250-f033-4a19-906a-267db2508f26",
        "outputId": "3380b272-55e3-41cf-cebe-5f578c5e525f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9900],\n",
            "         [0.8500],\n",
            "         [0.8900],\n",
            "         [0.9400],\n",
            "         [0.9900],\n",
            "         [0.9900],\n",
            "         [0.9900],\n",
            "         [0.9900],\n",
            "         [0.9000]]])\n"
          ]
        }
      ],
      "source": [
        "targets = torch.tensor([[0, 9, 10, 11, 4, 5, 6, 7, 8]])\n",
        "\n",
        "# 확률을 추출합니다.\n",
        "probabilities = torch.gather(model_outputs, 2, targets.unsqueeze(2))\n",
        "\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34d790d-3353-4185-a388-688534604875",
      "metadata": {
        "id": "c34d790d-3353-4185-a388-688534604875"
      },
      "source": [
        "[TorchMetric의 혼잡도 문서](https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html)에 따르면 입력은 확률 점수입니다.\n",
        "\n",
        "> - ``preds`` (:class:`~torch.Tensor`): Logits or a unnormalized score assigned to each token in a sequence with shape [batch_size, seq_len, vocab_size], which is the output of a language model. Scores will be normalized internally using softmax.\n",
        "\n",
        "따라서 확률을 그대로 전달하면 결과가 부풀려집니다. 하지만 로그 확률을 전달하면 앞의 결과를 재현할 수 있습니다.\n",
        "but the results are inflated when providing the inputs directly. However, when providing log-probabilities, we can reproduce the results from earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5f4420eb-2cac-4baf-931b-1415fa152226",
      "metadata": {
        "id": "5f4420eb-2cac-4baf-931b-1415fa152226",
        "outputId": "058c2318-d0d3-4dfd-dc49-1d93ee74165e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchmetrics version: 1.6.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0567)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import torchmetrics\n",
        "from torchmetrics.text import Perplexity\n",
        "\n",
        "print(\"torchmetrics version:\", torchmetrics.__version__)\n",
        "\n",
        "perp = Perplexity()\n",
        "perp(torch.log(model_outputs), targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c1ed8c-ddbe-4902-bb56-53f2d9ecc77e",
      "metadata": {
        "tags": [],
        "id": "04c1ed8c-ddbe-4902-bb56-53f2d9ecc77e"
      },
      "source": [
        "## 파이토치로 계산하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59122c21-dd97-417a-9221-fbb96523b104",
      "metadata": {
        "id": "59122c21-dd97-417a-9221-fbb96523b104"
      },
      "source": [
        "파이토치의 `torch.nn.functional.cross_entropy`는 로짓을 입력으로 기대하므로, (`torch.log_softmax(logits)`의 결과인) 확률을 입력으로 받는 음의 로그 우도 손실(negative log-likelihood loss)을 사용합니다.\n",
        "\n",
        "실제로 모델이 (확률 대신에) 로짓을 반환한다면 수치적 안정성과 효율성을 위해 `torch.nn.functional.nll_loss` 대신에 `torch.nn.functional.cross_entropy`를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2de93e09-f0c2-4bf0-9e8b-539f7d070f65",
      "metadata": {
        "id": "2de93e09-f0c2-4bf0-9e8b-539f7d070f65",
        "outputId": "6f5f90d6-7af8-47bd-a86d-f5ce3fd3c59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model_outputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "78682c83-7d77-4f7f-98d0-eb271a55540b",
      "metadata": {
        "id": "78682c83-7d77-4f7f-98d0-eb271a55540b",
        "outputId": "8538c251-8fa4-4697-af06-a4ef9ef2290d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0780aa39-4e34-45cb-9fde-180e3fac6e6f",
      "metadata": {
        "id": "0780aa39-4e34-45cb-9fde-180e3fac6e6f",
        "outputId": "60cab002-f3c9-4130-c5ed-2d98a90e863a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0567214488983154"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pytorch_perplexity(prob, target):\n",
        "\n",
        "    log_prob = torch.log(prob)\n",
        "    loss = F.nll_loss(log_prob, target, reduction='mean')\n",
        "    perplexity = torch.exp(loss)\n",
        "    return perplexity.item()\n",
        "\n",
        "pytorch_perplexity(model_outputs[0], targets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad1f198a-ca6c-4fc8-a1b6-f32916e12cbf",
      "metadata": {
        "id": "ad1f198a-ca6c-4fc8-a1b6-f32916e12cbf"
      },
      "source": [
        "## 밑이 2인 로드와 자연 로그를 사용한 혼잡도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "76c45995-f536-4380-8c90-43b10686a202",
      "metadata": {
        "id": "76c45995-f536-4380-8c90-43b10686a202",
        "outputId": "7d748ada-c266-49c6-9ab1-622db1c21700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1의 혼잡도: 1.0567214564189926\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_perplexity_base2(probabilities):\n",
        "    log_probs = np.log2(probabilities)\n",
        "    avg_log_prob = np.mean(log_probs)\n",
        "    perplexity = 2 ** (-avg_log_prob)\n",
        "    return perplexity\n",
        "\n",
        "true_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "sentence_1 = \"The fast black cat jumps over the lazy dog\"\n",
        "\n",
        "s1_word_proba = [0.99, 0.85, 0.89, 0.94, 0.99, 0.99, 0.99, 0.99, 0.90]\n",
        "perplex = calculate_perplexity_base2(s1_word_proba)\n",
        "print(\"문장 1의 혼잡도:\", perplex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0769ae64-0363-4987-af5e-167bdb9ce773",
      "metadata": {
        "id": "0769ae64-0363-4987-af5e-167bdb9ce773",
        "outputId": "c62daa69-0324-43fc-9a9f-0692234ac073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1의 혼잡도: 1.0567214564189926\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_perplexity_natural(probabilities):\n",
        "    log_probs = np.log(probabilities)\n",
        "    avg_log_prob = np.mean(log_probs)\n",
        "    perplexity = np.e ** (-avg_log_prob)\n",
        "    return perplexity\n",
        "\n",
        "true_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "sentence_1 = \"The fast black cat jumps over the lazy dog\"\n",
        "\n",
        "s1_word_proba = [0.99, 0.85, 0.89, 0.94, 0.99, 0.99, 0.99, 0.99, 0.90]\n",
        "perplex = calculate_perplexity_natural(s1_word_proba)\n",
        "print(\"문장 1의 혼잡도:\", perplex)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}